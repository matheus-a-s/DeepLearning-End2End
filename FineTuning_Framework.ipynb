{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1 - Consult GPU, or CPU, Disponibility**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using GPU == True\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "config = tf.compat.v1.ConfigProto(\n",
    "    gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.8)\n",
    "    # device_count = {'GPU': 1}\n",
    ")\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "tf.keras.backend.set_session(session)\n",
    "\n",
    "print(\"\\nUsing GPU ==\", tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2 - Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import keras\n",
    "from PIL import Image\n",
    "from keras import backend as tf\n",
    "from scipy import misc\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import csv\n",
    "import itertools\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.applications.nasnet import NASNetMobile\n",
    "from keras.applications.nasnet import NASNetLarge\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.applications.densenet import DenseNet169\n",
    "from keras.applications.densenet import DenseNet201\n",
    "\n",
    "from keras.applications.inception_resnet_v2 import preprocess_input as ppi_inceptionresnet_v2\n",
    "from keras.applications.vgg16 import preprocess_input as ppi_vgg16\n",
    "from keras.applications.vgg19 import preprocess_input as ppi_vgg19\n",
    "from keras.applications.xception import preprocess_input as ppi_xception\n",
    "from keras.applications.resnet50 import preprocess_input as ppi_resnet50\n",
    "from keras.applications.inception_v3 import preprocess_input as ppi_inception_v3\n",
    "from keras.applications.mobilenet import preprocess_input as ppi_mobilenet\n",
    "from keras.applications.nasnet import preprocess_input as ppi_nasnet\n",
    "from keras.applications.densenet import preprocess_input as ppi_densenet\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.layers import Input\n",
    "\n",
    "from keras.utils import np_utils\n",
    "\n",
    "\n",
    "#np.set_printoptions(threshold=np.nan)\n",
    "keras.backend.backend()\n",
    "\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "import keras.backend as K\n",
    "from keras.preprocessing import image\n",
    "\n",
    "import time\n",
    "current_milli_time = lambda: int(round(time.time() * 1000))\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import svm\n",
    "\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import *\n",
    "\n",
    "def tp(y_true, y_pred): return confusion_matrix(y_true, y_pred)[0, 0]\n",
    "def tn(y_true, y_pred): return confusion_matrix(y_true, y_pred)[0, 0]\n",
    "def fp(y_true, y_pred): return confusion_matrix(y_true, y_pred)[1, 0]\n",
    "def fn(y_true, y_pred): return confusion_matrix(y_true, y_pred)[0, 1]\n",
    "\n",
    "# accuracy, precision, sensitivity, specificity, f1_score, process_time\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from imblearn.metrics import specificity_score\n",
    "from imblearn.metrics import sensitivity_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BÃ”NUS: FINE-TUNING ON VGG16 BY KERAS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg_conv = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "vgg_conv.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x7f8cfe666860> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f8cfa9146d8> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f8cfa914828> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f8cfa9059e8> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f8cfa905d68> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f8cf80b0710> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f8cf805f8d0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f8cf805f7b8> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f8cf808e518> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f8cf803d0f0> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f8cf8053cf8> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f8cf8053be0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f8ce3fef470> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f8ce3f889b0> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f8ce3fb78d0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f8ce3fb7780> True\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f8ce3f04080> True\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f8ce3f14a58> True\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f8ce3f2ff28> True\n"
     ]
    }
   ],
   "source": [
    "# Freeze the layers except the last 4 layers\n",
    "for layer in vgg_conv.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# Check the trainable status of the individual layers\n",
    "for layer in vgg_conv.layers:\n",
    "    print(layer, layer.trainable)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16_input (InputLayer)     (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Model)                (None, 7, 7, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 2050      \n",
      "=================================================================\n",
      "Total params: 15,242,050\n",
      "Trainable params: 7,606,786\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import optimizers\n",
    " \n",
    "# Create the model\n",
    "base_model = models.Sequential()\n",
    " \n",
    "# Add the vgg convolutional base model\n",
    "base_model.add(vgg_conv)\n",
    " \n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "\n",
    "# and a logistic layer -- let's say we have 3 classes\n",
    "predictions = Dense(2, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    " \n",
    "# Show a summary of the model. Check the number of trainable parameters\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "\n",
    "# Compile the model\n",
    "# model.compile(loss='categorical_crossentropy',\n",
    "#               optimizer=SGD(lr=0.0001),\n",
    "#               metrics=['acc'])\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=SGD(lr=0.0001),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6663, 224, 224, 3) (6663,)\n",
      "(5330, 224, 224, 3) (5330,)\n",
      "(5330, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "path = \"./dataset/DDSM_ROI/mass&B2&B5_augmentation/FINE_TUNING\"\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "# img_class2 = 0\n",
    "for classe in list([0,1]):\n",
    "    folderPath = path+os.sep+str(classe)\n",
    "    for subdir, dirs, files in os.walk(folderPath):\n",
    "        for i, name in enumerate(files):\n",
    "            img = cv2.imread(subdir+os.sep+name)\n",
    "            img = cv2.resize(img, (224,224))\n",
    "            X.append(img)\n",
    "\n",
    "            img_class = classe\n",
    "\n",
    "    #         img_class = int(name.split(\"_\")[0])\n",
    "    #         if img_class == 1:\n",
    "    #             img_class2 = 0\n",
    "    #         if img_class == 2:\n",
    "    #             img_class2 = 0\n",
    "    #         if img_class == 5:\n",
    "    #             img_class2 = 1    \n",
    "            y.append(img_class)\n",
    "        \n",
    "X = np.asarray(X)\n",
    "y = np.asarray(y)\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "X_train = ppi_vgg16(X_train)\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AM: Adjust label to One-Hot encoding\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "#AM: Transform values 1 to 000000001, 2 to 000000010, 3 to 000000100, etc\n",
    "y_train_categ = to_categorical(y_train) \n",
    "y_test_categ = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0], y_train_categ[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/matheus-a-s/.MyEnv/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 5330 samples, validate on 1333 samples\n",
      "Epoch 1/200\n",
      "5330/5330 [==============================] - 307s 58ms/step - loss: 0.2884 - acc: 0.9066 - val_loss: 0.2501 - val_acc: 0.9310\n",
      "Epoch 2/200\n",
      "5330/5330 [==============================] - 286s 54ms/step - loss: 0.2352 - acc: 0.9295 - val_loss: 0.2514 - val_acc: 0.9295\n",
      "Epoch 3/200\n",
      "5330/5330 [==============================] - 285s 53ms/step - loss: 0.2279 - acc: 0.9304 - val_loss: 0.2454 - val_acc: 0.9310\n",
      "Epoch 4/200\n",
      "5330/5330 [==============================] - 285s 53ms/step - loss: 0.2231 - acc: 0.9306 - val_loss: 0.2419 - val_acc: 0.9317\n",
      "Epoch 5/200\n",
      "5330/5330 [==============================] - 285s 53ms/step - loss: 0.2189 - acc: 0.9315 - val_loss: 0.2410 - val_acc: 0.9310\n",
      "Epoch 6/200\n",
      "5330/5330 [==============================] - 285s 53ms/step - loss: 0.2156 - acc: 0.9326 - val_loss: 0.2410 - val_acc: 0.9310\n",
      "Epoch 7/200\n",
      "5330/5330 [==============================] - 285s 54ms/step - loss: 0.2122 - acc: 0.9334 - val_loss: 0.2394 - val_acc: 0.9325\n",
      "Epoch 8/200\n",
      "5330/5330 [==============================] - 285s 53ms/step - loss: 0.2098 - acc: 0.9336 - val_loss: 0.2366 - val_acc: 0.9302\n",
      "Epoch 9/200\n",
      "5330/5330 [==============================] - 286s 54ms/step - loss: 0.2071 - acc: 0.9349 - val_loss: 0.2352 - val_acc: 0.9317\n",
      "Epoch 10/200\n",
      "5330/5330 [==============================] - 285s 54ms/step - loss: 0.2048 - acc: 0.9349 - val_loss: 0.2358 - val_acc: 0.9317\n",
      "Epoch 11/200\n",
      "5330/5330 [==============================] - 285s 53ms/step - loss: 0.2020 - acc: 0.9358 - val_loss: 0.2372 - val_acc: 0.9325\n",
      "Epoch 12/200\n",
      "5330/5330 [==============================] - 285s 53ms/step - loss: 0.2003 - acc: 0.9353 - val_loss: 0.2363 - val_acc: 0.9325\n",
      "Epoch 13/200\n",
      "5330/5330 [==============================] - 285s 53ms/step - loss: 0.1983 - acc: 0.9370 - val_loss: 0.2336 - val_acc: 0.9317\n",
      "Epoch 14/200\n",
      "5330/5330 [==============================] - 285s 53ms/step - loss: 0.1961 - acc: 0.9371 - val_loss: 0.2360 - val_acc: 0.9310\n",
      "Epoch 15/200\n",
      "5330/5330 [==============================] - 285s 53ms/step - loss: 0.1937 - acc: 0.9381 - val_loss: 0.2301 - val_acc: 0.9325\n",
      "Epoch 16/200\n",
      "5330/5330 [==============================] - 285s 54ms/step - loss: 0.1923 - acc: 0.9392 - val_loss: 0.2325 - val_acc: 0.9317\n",
      "Epoch 17/200\n",
      "5330/5330 [==============================] - 285s 54ms/step - loss: 0.1900 - acc: 0.9402 - val_loss: 0.2335 - val_acc: 0.9347\n",
      "Epoch 18/200\n",
      "5330/5330 [==============================] - 285s 54ms/step - loss: 0.1879 - acc: 0.9403 - val_loss: 0.2302 - val_acc: 0.9332\n",
      "Epoch 19/200\n",
      "5330/5330 [==============================] - 285s 54ms/step - loss: 0.1866 - acc: 0.9411 - val_loss: 0.2324 - val_acc: 0.9355\n",
      "Epoch 20/200\n",
      "5330/5330 [==============================] - 290s 54ms/step - loss: 0.1845 - acc: 0.9418 - val_loss: 0.2308 - val_acc: 0.9340\n",
      "Epoch 21/200\n",
      "5330/5330 [==============================] - 287s 54ms/step - loss: 0.1823 - acc: 0.9418 - val_loss: 0.2284 - val_acc: 0.9340\n",
      "Epoch 22/200\n",
      "5330/5330 [==============================] - 296s 56ms/step - loss: 0.1804 - acc: 0.9424 - val_loss: 0.2312 - val_acc: 0.9340\n",
      "Epoch 23/200\n",
      "5330/5330 [==============================] - 285s 53ms/step - loss: 0.1793 - acc: 0.9426 - val_loss: 0.2283 - val_acc: 0.9370\n",
      "Epoch 24/200\n",
      "5330/5330 [==============================] - 285s 54ms/step - loss: 0.1771 - acc: 0.9432 - val_loss: 0.2310 - val_acc: 0.9340\n",
      "Epoch 25/200\n",
      "5330/5330 [==============================] - 285s 53ms/step - loss: 0.1759 - acc: 0.9439 - val_loss: 0.2280 - val_acc: 0.9340\n",
      "Epoch 26/200\n",
      "5330/5330 [==============================] - 285s 54ms/step - loss: 0.1741 - acc: 0.9433 - val_loss: 0.2290 - val_acc: 0.9347\n",
      "Epoch 27/200\n",
      "5330/5330 [==============================] - 285s 53ms/step - loss: 0.1725 - acc: 0.9441 - val_loss: 0.2269 - val_acc: 0.9347\n",
      "Epoch 28/200\n",
      "5330/5330 [==============================] - 285s 54ms/step - loss: 0.1706 - acc: 0.9450 - val_loss: 0.2265 - val_acc: 0.9355\n",
      "Epoch 29/200\n",
      "5330/5330 [==============================] - 287s 54ms/step - loss: 0.1691 - acc: 0.9456 - val_loss: 0.2289 - val_acc: 0.9295\n",
      "Epoch 30/200\n",
      "5330/5330 [==============================] - 301s 56ms/step - loss: 0.1673 - acc: 0.9450 - val_loss: 0.2231 - val_acc: 0.9355\n",
      "Epoch 31/200\n",
      "5330/5330 [==============================] - 327s 61ms/step - loss: 0.1661 - acc: 0.9467 - val_loss: 0.2226 - val_acc: 0.9347\n",
      "Epoch 32/200\n",
      "5330/5330 [==============================] - 380s 71ms/step - loss: 0.1638 - acc: 0.9471 - val_loss: 0.2181 - val_acc: 0.9355\n",
      "Epoch 33/200\n",
      "5330/5330 [==============================] - 321s 60ms/step - loss: 0.1627 - acc: 0.9469 - val_loss: 0.2221 - val_acc: 0.9340\n",
      "Epoch 34/200\n",
      "5330/5330 [==============================] - 300s 56ms/step - loss: 0.1613 - acc: 0.9482 - val_loss: 0.2179 - val_acc: 0.9332\n",
      "Epoch 35/200\n",
      "5330/5330 [==============================] - 300s 56ms/step - loss: 0.1599 - acc: 0.9486 - val_loss: 0.2187 - val_acc: 0.9340\n",
      "Epoch 36/200\n",
      "5330/5330 [==============================] - 300s 56ms/step - loss: 0.1585 - acc: 0.9482 - val_loss: 0.2180 - val_acc: 0.9340\n",
      "Epoch 37/200\n",
      "5330/5330 [==============================] - 300s 56ms/step - loss: 0.1567 - acc: 0.9501 - val_loss: 0.2204 - val_acc: 0.9340\n",
      "Epoch 38/200\n",
      "5330/5330 [==============================] - 300s 56ms/step - loss: 0.1550 - acc: 0.9497 - val_loss: 0.2184 - val_acc: 0.9332\n",
      "Epoch 39/200\n",
      "5330/5330 [==============================] - 299s 56ms/step - loss: 0.1535 - acc: 0.9512 - val_loss: 0.2171 - val_acc: 0.9347\n",
      "Epoch 40/200\n",
      "5330/5330 [==============================] - 299s 56ms/step - loss: 0.1521 - acc: 0.9505 - val_loss: 0.2164 - val_acc: 0.9347\n",
      "Epoch 41/200\n",
      "5330/5330 [==============================] - 300s 56ms/step - loss: 0.1507 - acc: 0.9514 - val_loss: 0.2165 - val_acc: 0.9340\n",
      "Epoch 42/200\n",
      "5330/5330 [==============================] - 300s 56ms/step - loss: 0.1493 - acc: 0.9514 - val_loss: 0.2129 - val_acc: 0.9347\n",
      "Epoch 43/200\n",
      "5330/5330 [==============================] - 304s 57ms/step - loss: 0.1476 - acc: 0.9522 - val_loss: 0.2141 - val_acc: 0.9377\n",
      "Epoch 44/200\n",
      "5330/5330 [==============================] - 301s 57ms/step - loss: 0.1461 - acc: 0.9527 - val_loss: 0.2148 - val_acc: 0.9370\n",
      "Epoch 45/200\n",
      "5330/5330 [==============================] - 301s 56ms/step - loss: 0.1451 - acc: 0.9535 - val_loss: 0.2118 - val_acc: 0.9355\n",
      "Epoch 46/200\n",
      "5330/5330 [==============================] - 301s 56ms/step - loss: 0.1436 - acc: 0.9546 - val_loss: 0.2134 - val_acc: 0.9370\n",
      "Epoch 47/200\n",
      "5330/5330 [==============================] - 300s 56ms/step - loss: 0.1415 - acc: 0.9548 - val_loss: 0.2107 - val_acc: 0.9370\n",
      "Epoch 48/200\n",
      "5330/5330 [==============================] - 300s 56ms/step - loss: 0.1406 - acc: 0.9553 - val_loss: 0.2120 - val_acc: 0.9362\n",
      "Epoch 49/200\n",
      "5330/5330 [==============================] - 301s 57ms/step - loss: 0.1390 - acc: 0.9555 - val_loss: 0.2077 - val_acc: 0.9400\n",
      "Epoch 50/200\n",
      "5330/5330 [==============================] - 301s 56ms/step - loss: 0.1379 - acc: 0.9557 - val_loss: 0.2083 - val_acc: 0.9407\n",
      "Epoch 51/200\n",
      "5330/5330 [==============================] - 300s 56ms/step - loss: 0.1361 - acc: 0.9563 - val_loss: 0.2056 - val_acc: 0.9407\n",
      "Epoch 52/200\n",
      "5330/5330 [==============================] - 302s 57ms/step - loss: 0.1349 - acc: 0.9572 - val_loss: 0.2097 - val_acc: 0.9362\n",
      "Epoch 53/200\n",
      "5330/5330 [==============================] - 301s 56ms/step - loss: 0.1334 - acc: 0.9582 - val_loss: 0.2072 - val_acc: 0.9362\n",
      "Epoch 54/200\n",
      "5330/5330 [==============================] - 299s 56ms/step - loss: 0.1327 - acc: 0.9578 - val_loss: 0.2045 - val_acc: 0.9407\n",
      "Epoch 55/200\n",
      "5330/5330 [==============================] - 301s 57ms/step - loss: 0.1307 - acc: 0.9589 - val_loss: 0.2037 - val_acc: 0.9400\n",
      "Epoch 56/200\n",
      "5330/5330 [==============================] - 302s 57ms/step - loss: 0.1294 - acc: 0.9595 - val_loss: 0.2051 - val_acc: 0.9400\n",
      "Epoch 57/200\n",
      "5330/5330 [==============================] - 301s 57ms/step - loss: 0.1280 - acc: 0.9598 - val_loss: 0.2024 - val_acc: 0.9407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/200\n",
      "5330/5330 [==============================] - 297s 56ms/step - loss: 0.1268 - acc: 0.9615 - val_loss: 0.2010 - val_acc: 0.9422\n",
      "Epoch 59/200\n",
      "5330/5330 [==============================] - 294s 55ms/step - loss: 0.1255 - acc: 0.9608 - val_loss: 0.2029 - val_acc: 0.9430\n",
      "Epoch 60/200\n",
      "5330/5330 [==============================] - 294s 55ms/step - loss: 0.1242 - acc: 0.9610 - val_loss: 0.2002 - val_acc: 0.9415\n",
      "Epoch 61/200\n",
      "5330/5330 [==============================] - 294s 55ms/step - loss: 0.1234 - acc: 0.9625 - val_loss: 0.2014 - val_acc: 0.9400\n",
      "Epoch 62/200\n",
      "5330/5330 [==============================] - 294s 55ms/step - loss: 0.1215 - acc: 0.9623 - val_loss: 0.2038 - val_acc: 0.9377\n",
      "Epoch 63/200\n",
      "5330/5330 [==============================] - 294s 55ms/step - loss: 0.1203 - acc: 0.9619 - val_loss: 0.1963 - val_acc: 0.9430\n",
      "Epoch 64/200\n",
      "5330/5330 [==============================] - 294s 55ms/step - loss: 0.1190 - acc: 0.9630 - val_loss: 0.1981 - val_acc: 0.9422\n",
      "Epoch 65/200\n",
      "5330/5330 [==============================] - 294s 55ms/step - loss: 0.1182 - acc: 0.9638 - val_loss: 0.1994 - val_acc: 0.9430\n",
      "Epoch 66/200\n",
      "5330/5330 [==============================] - 294s 55ms/step - loss: 0.1163 - acc: 0.9645 - val_loss: 0.1967 - val_acc: 0.9422\n",
      "Epoch 67/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.1151 - acc: 0.9651 - val_loss: 0.1955 - val_acc: 0.9437\n",
      "Epoch 68/200\n",
      "5330/5330 [==============================] - 294s 55ms/step - loss: 0.1136 - acc: 0.9640 - val_loss: 0.1995 - val_acc: 0.9392\n",
      "Epoch 69/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.1129 - acc: 0.9649 - val_loss: 0.1966 - val_acc: 0.9422\n",
      "Epoch 70/200\n",
      "5330/5330 [==============================] - 294s 55ms/step - loss: 0.1115 - acc: 0.9644 - val_loss: 0.1938 - val_acc: 0.9437\n",
      "Epoch 71/200\n",
      "5330/5330 [==============================] - 294s 55ms/step - loss: 0.1103 - acc: 0.9645 - val_loss: 0.1974 - val_acc: 0.9415\n",
      "Epoch 72/200\n",
      "5330/5330 [==============================] - 294s 55ms/step - loss: 0.1090 - acc: 0.9660 - val_loss: 0.1975 - val_acc: 0.9422\n",
      "Epoch 73/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.1076 - acc: 0.9657 - val_loss: 0.1949 - val_acc: 0.9415\n",
      "Epoch 74/200\n",
      "5330/5330 [==============================] - 294s 55ms/step - loss: 0.1067 - acc: 0.9668 - val_loss: 0.1922 - val_acc: 0.9437\n",
      "Epoch 75/200\n",
      "5330/5330 [==============================] - 294s 55ms/step - loss: 0.1053 - acc: 0.9670 - val_loss: 0.1937 - val_acc: 0.9415\n",
      "Epoch 76/200\n",
      "5330/5330 [==============================] - 294s 55ms/step - loss: 0.1045 - acc: 0.9672 - val_loss: 0.1947 - val_acc: 0.9407\n",
      "Epoch 77/200\n",
      "5330/5330 [==============================] - 294s 55ms/step - loss: 0.1033 - acc: 0.9672 - val_loss: 0.1932 - val_acc: 0.9407\n",
      "Epoch 78/200\n",
      "5330/5330 [==============================] - 294s 55ms/step - loss: 0.1022 - acc: 0.9685 - val_loss: 0.1923 - val_acc: 0.9430\n",
      "Epoch 79/200\n",
      "5330/5330 [==============================] - 294s 55ms/step - loss: 0.1010 - acc: 0.9690 - val_loss: 0.1896 - val_acc: 0.9460\n",
      "Epoch 80/200\n",
      "5330/5330 [==============================] - 294s 55ms/step - loss: 0.0996 - acc: 0.9681 - val_loss: 0.1848 - val_acc: 0.9467\n",
      "Epoch 81/200\n",
      "5330/5330 [==============================] - 294s 55ms/step - loss: 0.0987 - acc: 0.9690 - val_loss: 0.1886 - val_acc: 0.9445\n",
      "Epoch 82/200\n",
      "5330/5330 [==============================] - 294s 55ms/step - loss: 0.0971 - acc: 0.9707 - val_loss: 0.1892 - val_acc: 0.9452\n",
      "Epoch 83/200\n",
      "5330/5330 [==============================] - 294s 55ms/step - loss: 0.0963 - acc: 0.9704 - val_loss: 0.1872 - val_acc: 0.9467\n",
      "Epoch 84/200\n",
      "5330/5330 [==============================] - 294s 55ms/step - loss: 0.0953 - acc: 0.9685 - val_loss: 0.1899 - val_acc: 0.9437\n",
      "Epoch 85/200\n",
      "5330/5330 [==============================] - 294s 55ms/step - loss: 0.0937 - acc: 0.9711 - val_loss: 0.1867 - val_acc: 0.9452\n",
      "Epoch 86/200\n",
      "5330/5330 [==============================] - 294s 55ms/step - loss: 0.0930 - acc: 0.9711 - val_loss: 0.1903 - val_acc: 0.9437\n",
      "Epoch 87/200\n",
      "5330/5330 [==============================] - 294s 55ms/step - loss: 0.0914 - acc: 0.9730 - val_loss: 0.1900 - val_acc: 0.9452\n",
      "Epoch 88/200\n",
      "5330/5330 [==============================] - 294s 55ms/step - loss: 0.0907 - acc: 0.9724 - val_loss: 0.1841 - val_acc: 0.9452\n",
      "Epoch 89/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0899 - acc: 0.9732 - val_loss: 0.1877 - val_acc: 0.9430\n",
      "Epoch 90/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0885 - acc: 0.9734 - val_loss: 0.1910 - val_acc: 0.9437\n",
      "Epoch 91/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0876 - acc: 0.9732 - val_loss: 0.1851 - val_acc: 0.9452\n",
      "Epoch 92/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0864 - acc: 0.9732 - val_loss: 0.1866 - val_acc: 0.9475\n",
      "Epoch 93/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0857 - acc: 0.9739 - val_loss: 0.1873 - val_acc: 0.9445\n",
      "Epoch 94/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0845 - acc: 0.9735 - val_loss: 0.1846 - val_acc: 0.9475\n",
      "Epoch 95/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0829 - acc: 0.9756 - val_loss: 0.1908 - val_acc: 0.9430\n",
      "Epoch 96/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0825 - acc: 0.9752 - val_loss: 0.1862 - val_acc: 0.9452\n",
      "Epoch 97/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0811 - acc: 0.9762 - val_loss: 0.1823 - val_acc: 0.9490\n",
      "Epoch 98/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0807 - acc: 0.9769 - val_loss: 0.1891 - val_acc: 0.9445\n",
      "Epoch 99/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0793 - acc: 0.9771 - val_loss: 0.1873 - val_acc: 0.9452\n",
      "Epoch 100/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0779 - acc: 0.9762 - val_loss: 0.1912 - val_acc: 0.9445\n",
      "Epoch 101/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0777 - acc: 0.9775 - val_loss: 0.1863 - val_acc: 0.9452\n",
      "Epoch 102/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0768 - acc: 0.9790 - val_loss: 0.1871 - val_acc: 0.9445\n",
      "Epoch 103/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0757 - acc: 0.9779 - val_loss: 0.1865 - val_acc: 0.9445\n",
      "Epoch 104/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0746 - acc: 0.9788 - val_loss: 0.1849 - val_acc: 0.9460\n",
      "Epoch 105/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0738 - acc: 0.9788 - val_loss: 0.1850 - val_acc: 0.9452\n",
      "Epoch 106/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0729 - acc: 0.9795 - val_loss: 0.1826 - val_acc: 0.9467\n",
      "Epoch 107/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0720 - acc: 0.9794 - val_loss: 0.1849 - val_acc: 0.9467\n",
      "Epoch 108/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0707 - acc: 0.9805 - val_loss: 0.1848 - val_acc: 0.9467\n",
      "Epoch 109/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0699 - acc: 0.9801 - val_loss: 0.1921 - val_acc: 0.9415\n",
      "Epoch 110/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0688 - acc: 0.9807 - val_loss: 0.1844 - val_acc: 0.9475\n",
      "Epoch 111/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0679 - acc: 0.9818 - val_loss: 0.1864 - val_acc: 0.9460\n",
      "Epoch 112/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0672 - acc: 0.9809 - val_loss: 0.1818 - val_acc: 0.9482\n",
      "Epoch 113/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0665 - acc: 0.9822 - val_loss: 0.1867 - val_acc: 0.9467\n",
      "Epoch 114/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0654 - acc: 0.9818 - val_loss: 0.1932 - val_acc: 0.9355\n",
      "Epoch 115/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0650 - acc: 0.9822 - val_loss: 0.1861 - val_acc: 0.9475\n",
      "Epoch 116/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0633 - acc: 0.9826 - val_loss: 0.1926 - val_acc: 0.9445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0627 - acc: 0.9824 - val_loss: 0.1827 - val_acc: 0.9475\n",
      "Epoch 118/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0618 - acc: 0.9820 - val_loss: 0.1823 - val_acc: 0.9467\n",
      "Epoch 119/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0605 - acc: 0.9837 - val_loss: 0.1932 - val_acc: 0.9445\n",
      "Epoch 120/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0598 - acc: 0.9829 - val_loss: 0.1868 - val_acc: 0.9422\n",
      "Epoch 121/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0601 - acc: 0.9837 - val_loss: 0.1854 - val_acc: 0.9475\n",
      "Epoch 122/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0585 - acc: 0.9833 - val_loss: 0.1818 - val_acc: 0.9482\n",
      "Epoch 123/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0574 - acc: 0.9844 - val_loss: 0.1860 - val_acc: 0.9482\n",
      "Epoch 124/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0567 - acc: 0.9835 - val_loss: 0.1872 - val_acc: 0.9482\n",
      "Epoch 125/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0560 - acc: 0.9846 - val_loss: 0.1833 - val_acc: 0.9467\n",
      "Epoch 126/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0550 - acc: 0.9852 - val_loss: 0.1816 - val_acc: 0.9482\n",
      "Epoch 127/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0546 - acc: 0.9848 - val_loss: 0.1825 - val_acc: 0.9482\n",
      "Epoch 128/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0535 - acc: 0.9850 - val_loss: 0.1835 - val_acc: 0.9482\n",
      "Epoch 129/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0532 - acc: 0.9865 - val_loss: 0.1843 - val_acc: 0.9475\n",
      "Epoch 130/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0522 - acc: 0.9865 - val_loss: 0.1898 - val_acc: 0.9475\n",
      "Epoch 131/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0513 - acc: 0.9857 - val_loss: 0.1882 - val_acc: 0.9490\n",
      "Epoch 132/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0509 - acc: 0.9861 - val_loss: 0.1885 - val_acc: 0.9460\n",
      "Epoch 133/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0497 - acc: 0.9869 - val_loss: 0.1843 - val_acc: 0.9490\n",
      "Epoch 134/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0490 - acc: 0.9871 - val_loss: 0.1844 - val_acc: 0.9452\n",
      "Epoch 135/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0483 - acc: 0.9874 - val_loss: 0.1870 - val_acc: 0.9475\n",
      "Epoch 136/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0480 - acc: 0.9880 - val_loss: 0.1882 - val_acc: 0.9475\n",
      "Epoch 137/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0472 - acc: 0.9874 - val_loss: 0.1875 - val_acc: 0.9460\n",
      "Epoch 138/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0466 - acc: 0.9886 - val_loss: 0.1915 - val_acc: 0.9475\n",
      "Epoch 139/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0457 - acc: 0.9884 - val_loss: 0.1912 - val_acc: 0.9467\n",
      "Epoch 140/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0454 - acc: 0.9889 - val_loss: 0.1869 - val_acc: 0.9445\n",
      "Epoch 141/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0446 - acc: 0.9889 - val_loss: 0.1910 - val_acc: 0.9460\n",
      "Epoch 142/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0438 - acc: 0.9889 - val_loss: 0.1887 - val_acc: 0.9460\n",
      "Epoch 143/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0432 - acc: 0.9893 - val_loss: 0.1940 - val_acc: 0.9467\n",
      "Epoch 144/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0422 - acc: 0.9895 - val_loss: 0.1900 - val_acc: 0.9445\n",
      "Epoch 145/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0422 - acc: 0.9897 - val_loss: 0.1928 - val_acc: 0.9392\n",
      "Epoch 146/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0414 - acc: 0.9901 - val_loss: 0.1883 - val_acc: 0.9430\n",
      "Epoch 147/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0405 - acc: 0.9901 - val_loss: 0.1911 - val_acc: 0.9437\n",
      "Epoch 148/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0403 - acc: 0.9906 - val_loss: 0.1952 - val_acc: 0.9377\n",
      "Epoch 149/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0399 - acc: 0.9904 - val_loss: 0.1916 - val_acc: 0.9460\n",
      "Epoch 150/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0390 - acc: 0.9908 - val_loss: 0.1915 - val_acc: 0.9460\n",
      "Epoch 151/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0381 - acc: 0.9914 - val_loss: 0.1913 - val_acc: 0.9475\n",
      "Epoch 152/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0378 - acc: 0.9904 - val_loss: 0.1928 - val_acc: 0.9460\n",
      "Epoch 153/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0374 - acc: 0.9916 - val_loss: 0.1914 - val_acc: 0.9482\n",
      "Epoch 154/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0368 - acc: 0.9908 - val_loss: 0.1947 - val_acc: 0.9445\n",
      "Epoch 155/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0364 - acc: 0.9919 - val_loss: 0.1946 - val_acc: 0.9445\n",
      "Epoch 156/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0358 - acc: 0.9914 - val_loss: 0.1942 - val_acc: 0.9475\n",
      "Epoch 157/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0352 - acc: 0.9917 - val_loss: 0.1921 - val_acc: 0.9452\n",
      "Epoch 158/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0345 - acc: 0.9927 - val_loss: 0.1946 - val_acc: 0.9452\n",
      "Epoch 159/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0341 - acc: 0.9921 - val_loss: 0.1978 - val_acc: 0.9407\n",
      "Epoch 160/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0335 - acc: 0.9919 - val_loss: 0.1954 - val_acc: 0.9460\n",
      "Epoch 161/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0331 - acc: 0.9925 - val_loss: 0.1960 - val_acc: 0.9445\n",
      "Epoch 162/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0323 - acc: 0.9932 - val_loss: 0.1995 - val_acc: 0.9445\n",
      "Epoch 163/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0321 - acc: 0.9929 - val_loss: 0.1999 - val_acc: 0.9445\n",
      "Epoch 164/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0319 - acc: 0.9927 - val_loss: 0.1961 - val_acc: 0.9437\n",
      "Epoch 165/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0314 - acc: 0.9931 - val_loss: 0.1979 - val_acc: 0.9430\n",
      "Epoch 166/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0305 - acc: 0.9932 - val_loss: 0.2014 - val_acc: 0.9347\n",
      "Epoch 167/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0302 - acc: 0.9931 - val_loss: 0.2002 - val_acc: 0.9407\n",
      "Epoch 168/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0299 - acc: 0.9934 - val_loss: 0.2028 - val_acc: 0.9445\n",
      "Epoch 169/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0295 - acc: 0.9936 - val_loss: 0.2012 - val_acc: 0.9445\n",
      "Epoch 170/200\n",
      "5330/5330 [==============================] - 296s 55ms/step - loss: 0.0287 - acc: 0.9944 - val_loss: 0.1990 - val_acc: 0.9460\n",
      "Epoch 171/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0282 - acc: 0.9942 - val_loss: 0.2021 - val_acc: 0.9437\n",
      "Epoch 172/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0280 - acc: 0.9944 - val_loss: 0.2071 - val_acc: 0.9377\n",
      "Epoch 173/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0278 - acc: 0.9936 - val_loss: 0.2060 - val_acc: 0.9400\n",
      "Epoch 174/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0275 - acc: 0.9940 - val_loss: 0.2053 - val_acc: 0.9400\n",
      "Epoch 175/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0269 - acc: 0.9944 - val_loss: 0.2014 - val_acc: 0.9355\n",
      "Epoch 176/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0263 - acc: 0.9953 - val_loss: 0.2047 - val_acc: 0.9415\n",
      "Epoch 177/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0262 - acc: 0.9953 - val_loss: 0.2045 - val_acc: 0.9422\n",
      "Epoch 178/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0254 - acc: 0.9947 - val_loss: 0.2015 - val_acc: 0.9445\n",
      "Epoch 179/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0253 - acc: 0.9959 - val_loss: 0.2038 - val_acc: 0.9445\n",
      "Epoch 180/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0246 - acc: 0.9957 - val_loss: 0.2077 - val_acc: 0.9415\n",
      "Epoch 181/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0245 - acc: 0.9955 - val_loss: 0.2050 - val_acc: 0.9437\n",
      "Epoch 182/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0241 - acc: 0.9962 - val_loss: 0.2047 - val_acc: 0.9422\n",
      "Epoch 183/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0238 - acc: 0.9962 - val_loss: 0.2045 - val_acc: 0.9385\n",
      "Epoch 184/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0236 - acc: 0.9953 - val_loss: 0.2074 - val_acc: 0.9347\n",
      "Epoch 185/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0233 - acc: 0.9957 - val_loss: 0.2093 - val_acc: 0.9385\n",
      "Epoch 186/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0229 - acc: 0.9961 - val_loss: 0.2091 - val_acc: 0.9370\n",
      "Epoch 187/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0227 - acc: 0.9964 - val_loss: 0.2090 - val_acc: 0.9407\n",
      "Epoch 188/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0223 - acc: 0.9966 - val_loss: 0.2115 - val_acc: 0.9430\n",
      "Epoch 189/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0218 - acc: 0.9968 - val_loss: 0.2127 - val_acc: 0.9310\n",
      "Epoch 190/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0217 - acc: 0.9968 - val_loss: 0.2160 - val_acc: 0.9302\n",
      "Epoch 191/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0212 - acc: 0.9966 - val_loss: 0.2142 - val_acc: 0.9355\n",
      "Epoch 192/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0207 - acc: 0.9966 - val_loss: 0.2125 - val_acc: 0.9370\n",
      "Epoch 193/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0207 - acc: 0.9970 - val_loss: 0.2118 - val_acc: 0.9392\n",
      "Epoch 194/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0202 - acc: 0.9972 - val_loss: 0.2136 - val_acc: 0.9385\n",
      "Epoch 195/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0203 - acc: 0.9977 - val_loss: 0.2134 - val_acc: 0.9422\n",
      "Epoch 196/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0197 - acc: 0.9974 - val_loss: 0.2200 - val_acc: 0.9287\n",
      "Epoch 197/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0197 - acc: 0.9970 - val_loss: 0.2142 - val_acc: 0.9310\n",
      "Epoch 198/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0193 - acc: 0.9970 - val_loss: 0.2126 - val_acc: 0.9355\n",
      "Epoch 199/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0189 - acc: 0.9977 - val_loss: 0.2142 - val_acc: 0.9347\n",
      "Epoch 200/200\n",
      "5330/5330 [==============================] - 295s 55ms/step - loss: 0.0187 - acc: 0.9979 - val_loss: 0.2150 - val_acc: 0.9392\n",
      "[0.017862340645064333, 0.997748613357544]\n",
      "CPU times: user 3h 14min 53s, sys: 57min 4s, total: 4h 11min 57s\n",
      "Wall time: 16h 27min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "plotfit = model.fit(X_train, y_train_categ,\n",
    "                    epochs=200,\n",
    "                    batch_size=40,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(X_test, y_test_categ))\n",
    "print(model.evaluate(X_train, y_train_categ, batch_size=40, verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(plotfit.history['acc'])\n",
    "plt.plot(plotfit.history['val_acc'])\n",
    "plt.legend(['Training', 'Validation'])\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "0 vgg16_input\n",
      "1 vgg16\n",
      "2 global_average_pooling2d_1\n",
      "3 dense_1\n",
      "4 dense_2\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16_input (InputLayer)     (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Model)                (None, 7, 7, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 7,079,424\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "for i in range(len(loaded_model.layers)):\n",
    "    layer = loaded_model.layers[i]\n",
    "    # summarize output shape\n",
    "    print(i, layer.name)\n",
    "\n",
    "new_model = Model(inputs=loaded_model.inputs, outputs=loaded_model.layers[2].output)\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".MyEnv",
   "language": "python",
   "name": ".myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
